{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/6f/Dauphine_logo_2019_-_Bleu.png\" style=\"width: 600px;\"/> \n",
    "</center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><span style=\"font-family:Arial Black;font-size:33px;color:darkblue\"> Master Economie Finance </span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><span style=\"font-family:Arial Black;font-size:27px;color:darkblue\">Application Lab – Portfolio Management</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><span style=\"font-family:Arial Black;font-size:20px;color:darkblue\">Time series data modelling\n",
    "</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas > /dev/null 2>&1\n",
    "!pip install numpy > /dev/null 2>&1\n",
    "!pip install yfinance > /dev/null 2>&1\n",
    "!pip install matplotlib > /dev/null 2>&1\n",
    "!pip install seaborn > /dev/null 2>&1\n",
    "!pip install arch > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE: Data download and transformation</b>:\n",
    "    <ul>\n",
    "        <li>Download the Close prices for the following tickers: \n",
    "            <code>'JPM', 'BAC', 'C', 'GS', 'MS'</code> \n",
    "            using <code>yfinance</code>. Set the start date to <code>'2010-01-01'</code> and the end date to <code>'2025-08-31'</code>.</li>\n",
    "        <li>Transform the Adjusted Close prices into log returns for each stock and times 100.\n",
    "        <li>Create a new DataFrame named <code>log_returns</code> to store the calculated log returns for all stocks.</li>\n",
    "        <li>Drop missing values (e.g., NaN values) resulting from the transformation. Hint: check the shift method for dataframe</li>\n",
    "        <li>Visualize the Price and log returns of <code>'JPM'</code> using the plot function of pyplot.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is stationary matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Stationarity (ADF Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "jpm_price = data['JPM'].to_numpy()\n",
    "\n",
    "adf_result = adfuller(jpm_price)\n",
    "print(\"ADF Statistic:\", adf_result[0])\n",
    "print(\"p-value:\", adf_result[1])\n",
    "print(\"Critical Values:\", adf_result[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see that the close price of JPM is not stationary, now test for log returns of JPM\n",
    "jpm_return = log_returns['JPM'].to_numpy()\n",
    "\n",
    "adf_result = adfuller(jpm_return)\n",
    "print(\"ADF Statistic:\", adf_result[0])\n",
    "print(\"p-value:\", adf_result[1])\n",
    "print(\"Critical Values:\", adf_result[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive (AR) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X_t = \\phi_0 + \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\dots + \\phi_p X_{t-p} + \\epsilon_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PACF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When modeling real data with an AR model, the order $p$ is unknown. Determining $p$ is called the problem of order selection. Common methods include the partial autocorrelation function (PACF) and the AIC or BIC criterion.\n",
    "\n",
    "Let $X_1, \\ldots, X_n, Y$ be random variables, and define\n",
    "\n",
    "$$\n",
    "L(Y|X_1, \\ldots, X_n) = \\arg\\min_{\\hat{Y}=b_0+b_1X_1+\\cdots+b_nX_n} E(Y-\\hat{Y})^2,\n",
    "$$\n",
    "\n",
    "which is called the best linear prediction of $Y$ using $X_1, \\ldots, X_n$. The correlation coefficient between $Y - L(Y|X_1, \\ldots, X_n)$ and $Z - L(Z|X_1, \\ldots, X_n)$ is called the **partial correlation coefficient** between $Y$ and $Z$ after removing the effect of $X_1, \\ldots, X_n$.\n",
    "\n",
    "For a stationary linear time series, for $n=1,2,\\ldots$, we have\n",
    "\n",
    "$$\n",
    "L(X_t | X_{t-1}, \\ldots, X_{t-n}) = \\phi_{n0} + \\phi_{n1} X_{t-1} + \\cdots + \\phi_{nn} X_{t-n},\n",
    "$$\n",
    "\n",
    "where $\\phi_{nj}, j=0,1,\\ldots,n$ are independent of $t$. $\\phi_{nn}$ is the **partial autocorrelation coefficient** of the time series $\\{X_t\\}$, and the sequence $\\{\\phi_{nn}\\}$ is called the **partial autocorrelation function (PACF)** of the time series $\\{X_t\\}$.\n",
    "\n",
    "In fact, $\\phi_{nn}$ is the partial correlation coefficient between $X_t$ and $X_{t-n}$ after removing the effect of $X_{t-1}, \\ldots, X_{t-(n-1)}$. In particular, $\\phi_{11} = \\rho_1$.\n",
    "\n",
    "The sample estimate of $\\phi_{nn}$, denoted $\\hat{\\phi}_{nn}, n=1,2,\\ldots$, is called the **sample partial autocorrelation function**. In Python, it can be estimated and plotted using plot_pacf() from statsmodels.\n",
    "\n",
    "If ${X_t}$ follows the AR($p$) model:\n",
    "\n",
    "$$\n",
    "X_t = \\phi_0 + \\phi_1 X_{t-1} + \\cdots + \\phi_p X_{t-p} + \\varepsilon_t, \\quad \\phi_p \\neq 0,\n",
    "$$\n",
    "\n",
    "this means that when predicting $X_t$ using a linear combination of $X_{t-1}, \\ldots, X_{t-p}$, only these lags are needed. Adding $X_{t-p-1}, X_{t-p-2}, \\ldots$ does not improve the prediction. This implies that $\\hat{\\phi}_{kk}=0, k>p$. This property is called the cut-off property of the PACF for AR models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "plot_pacf(jpm_return, lags=40)\n",
    "plt.title(\"PACF Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are generally 2 ways of fitting a AR model, ARIMA is perfered, standard errors are more precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "ar_model = AutoReg(jpm_return, lags=1).fit()\n",
    "ar_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "ar_model = ARIMA(jpm_return, order=(1, 0, 0)).fit()\n",
    "ar_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akaike Information Criterion\n",
    "\n",
    "It is defined as:\n",
    "\n",
    "$$\n",
    "AIC = -\\frac{2}{T}\\ln(\\text{likelihood value}) + \\frac{2}{T}(\\text{number of parameters}),\n",
    "$$\n",
    "\n",
    "where the likelihood value is the likelihood evaluated at the maximum likelihood estimates of the parameters.  \n",
    "When the model is a higher-order AR(p), i.e., $\\{\\varepsilon_t\\}$ is an independent $N(0,\\sigma^2)$ sequence in the AR(p) model, the AIC formula is:\n",
    "\n",
    "$$\n",
    "AIC(k) = \\ln \\hat{\\sigma}_k^2 + \\frac{2k}{T},\n",
    "$$\n",
    "\n",
    "where $k$ is the order of the model, and $\\hat{\\sigma}_k^2$ is the maximum likelihood estimate of the variance of $\\varepsilon_t$ under order $k$.  \n",
    "$\\ln \\hat{\\sigma}_k^2$ represents the goodness of fit of the model to the data: the smaller the value, the better the fit.  \n",
    "The term $\\frac{2k}{T}$ is a penalty for model complexity: the larger the $k$, the more complex the model, the less stable it is, and the worse its adaptability to future situations.  \n",
    "Choosing $k$ that minimizes $AIC(k)$ within a certain range achieves a trade-off between goodness of fit and model simplicity.\n",
    "\n",
    "---\n",
    "\n",
    "Bayesian Information Criterion\n",
    "\n",
    "Another commonly used information criterion is the BIC. For a higher-order AR model:\n",
    "\n",
    "$$\n",
    "BIC(k) = \\ln \\hat{\\sigma}_k^2 + \\frac{k \\ln T}{T},\n",
    "$$\n",
    "\n",
    "BIC tends to select a lower-order model than AIC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ar_model.aic)\n",
    "print(ar_model.bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_model.bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for next period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_model.forecast(steps = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE: Find the Best Lag Order Using BIC</b>:\n",
    "    <ul>        \n",
    "        <li>Fit an AR model for lag orders ranging from 1 to 10. Hint: Use statsmodels ARIMA function.</li> \n",
    "        <li>For each lag order, calculate the BIC values of the fitted AR model.</li>\n",
    "        <li>Create a list to store the  BIC values corresponding to each lag order.</li>\n",
    "        <li>Find the lag order with the minimum BIC values.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_residuals = ar_model.resid\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ar_residuals, label='Residuals', color='blue')\n",
    "plt.title(\"Residuals Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Ljung-Box test\n",
    "ljung_box_result = acorr_ljungbox(ar_residuals, lags=[np.floor(np.sqrt(len(jpm_return)))], return_df=True)\n",
    "print(ljung_box_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Average (MA) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X_t = \\mu + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\dots + \\theta_q \\epsilon_{t-q}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MA (Moving Average) model describes the current value (the value of the time series) as being determined by the weighted sum of random error terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the lag using Autocorrelation Function(ACF) plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(jpm_return, lags=40)\n",
    "plt.title(\"ACF Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_model = ARIMA(jpm_return, order=(0, 0, 2)).fit()\n",
    "ma_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for next period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = ma_model.forecast(steps=1)\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_residuals = ma_model.resid\n",
    "\n",
    "ljung_box_result = acorr_ljungbox(ma_residuals, lags=[np.floor(np.sqrt(len(jpm_return)))], return_df=True)\n",
    "print(ljung_box_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive Moving Average (ARMA) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X_t = \\mu + \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\dots + \\phi_p X_{t-p} + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\dots + \\theta_q \\epsilon_{t-q}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_model = ARIMA(jpm_return, order=(2, 0, 2)).fit()\n",
    "arma_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_model.forecast(steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_residuals = arma_model.resid\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(arma_residuals, label='Residuals', color='blue')\n",
    "plt.title(\"Residuals Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ljung_box_result = acorr_ljungbox(arma_residuals, lags=[np.floor(np.sqrt(len(jpm_return)))], return_df=True)\n",
    "print(ljung_box_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Autoregressive Conditional Heteroskedasticity (GARCH) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X_t = \\mu + \\epsilon_t\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\epsilon_t = \\sigma_t z_t\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_t^2 = \\alpha_0 + \\sum_{i=1}^{q} \\alpha_i \\epsilon_{t-i}^2 + \\sum_{j=1}^{p} \\beta_j \\sigma_{t-j}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose mean = 'Zero', 'Constant', 'AR'\n",
    "\n",
    "dist = 'Normal', 't', 'skewt', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garch_model = arch_model(jpm_return, mean='Zero', vol='GARCH', p=1, q=1, dist='Normal').fit()\n",
    "garch_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract residuals\n",
    "eps = garch_model.resid               # epsilon_t\n",
    "sigma = garch_model.conditional_volatility    # sigma_t\n",
    "z = garch_model.std_resid                    # standardized residuals: z_t = eps_t / sigma_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals over time\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(eps, lw=0.8)\n",
    "plt.title(\"Residuals (epsilon_t)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Standardized residuals over time\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(z, lw=0.8)\n",
    "plt.title(\"Standardized Residuals (z_t)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"z_t\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, probplot, skew, kurtosis\n",
    "\n",
    "# Histogram of z with standard normal pdf\n",
    "plt.figure(figsize=(6, 4))\n",
    "count, bins, _ = plt.hist(z, bins=50, density=True, alpha=0.5, edgecolor=\"none\", label=\"z_t histogram\")\n",
    "x = np.linspace(z.min(), z.max(), 400)\n",
    "plt.plot(x, norm.pdf(x), \"k--\", label=\"N(0,1) pdf\")\n",
    "plt.title(\"Standardized Residuals: Histogram vs N(0,1)\")\n",
    "plt.xlabel(\"z_t\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Normal Q-Q plot for z\n",
    "plt.figure(figsize=(4.5, 4.5))\n",
    "probplot(z, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q Plot of z_t\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t as student_t, probplot\n",
    "\n",
    "am_t = arch_model(jpm_return, mean='Zero', vol='GARCH', p=1, q=1, dist='t')\n",
    "res_t = am_t.fit()\n",
    "\n",
    "#Extract standardized residuals and estimated df\n",
    "z_t = res_t.std_resid     # standardized residuals: epsilon_t / sigma_t\n",
    "df_t = float(res_t.params.get(\"nu\"))  # estimated degrees of freedom\n",
    "\n",
    "#Histogram with Student-t pdf \n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(z_t, bins=50, density=True, alpha=0.5, edgecolor=\"none\", label=\"z_t histogram\")\n",
    "x = np.linspace(z_t.min(), z_t.max(), 400)\n",
    "plt.plot(x, student_t.pdf(x, df=df_t), \"r--\", label=f\"t pdf (df={df_t:.1f})\")\n",
    "plt.title(\"Standardized Residuals: Histogram vs t pdf\")\n",
    "plt.xlabel(\"z_t\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Student-t Q-Q plot for z_t\n",
    "plt.figure(figsize=(4.5, 4.5))\n",
    "probplot(z_t, dist=student_t, sparams=(df_t,), plot=plt)\n",
    "plt.title(f\"t Q-Q Plot of z_t (df≈{df_t:.1f})\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for next period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_t.forecast(horizon=1).variance.values[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE:</b>\n",
    "    <ul>\n",
    "        <li>Write a loop to find the best GARCH model order (<code>p</code>, <code>q</code>) where <code>p</code> ranges from 1 to 5 and <code>q</code> ranges from 1 to 5, using the Bayesian Information Criterion (BIC) for selection.</li>\n",
    "        <li>Using a rolling window of 252 observations, predict the volatility for the next period for each window.</li>\n",
    "        <li>Plot the squared predicted volatility against the squared returns for comparison.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
