{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/6f/Dauphine_logo_2019_-_Bleu.png\" style=\"width: 600px;\"/> \n",
    "</center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><span style=\"font-family:Arial Black;font-size:33px;color:darkblue\"> Master Economie Finance </span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><span style=\"font-family:Arial Black;font-size:27px;color:darkblue\">Application Lab – Portfolio Management</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><span style=\"font-family:Arial Black;font-size:20px;color:darkblue\">Time series data modelling\n",
    "</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas > /dev/null 2>&1\n",
    "!pip install numpy > /dev/null 2>&1\n",
    "!pip install yfinance > /dev/null 2>&1\n",
    "!pip install matplotlib > /dev/null 2>&1\n",
    "!pip install seaborn > /dev/null 2>&1\n",
    "!pip install arch > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE: Data download and transformation</b>:\n",
    "    <ul>\n",
    "        <li>Download the Close prices for the following tickers: \n",
    "            <code>'JPM', 'BAC', 'C', 'GS', 'MS'</code> \n",
    "            using <code>yfinance</code>. Set the start date to <code>'2010-01-01'</code> and the end date to <code>'2025-08-31'</code>.</li>\n",
    "        <li>Transform the Adjusted Close prices into log returns for each stock and times 100.\n",
    "        <li>Create a new DataFrame named <code>log_returns</code> to store the calculated log returns for all stocks.</li>\n",
    "        <li>Drop missing values (e.g., NaN values) resulting from the transformation.</li>\n",
    "        <li>Visualize the Price and log returns of <code>'JPM'</code> using line plot.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is stationary matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Stationarity (ADF Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "jpm_price = data['JPM'].to_numpy()\n",
    "\n",
    "adf_result = adfuller(jpm_price)\n",
    "print(\"ADF Statistic:\", adf_result[0])\n",
    "print(\"p-value:\", adf_result[1])\n",
    "print(\"Critical Values:\", adf_result[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see that the close price of JPM is not stationary, now test for log returns of JPM\n",
    "jpm_return = log_returns['JPM'].to_numpy()\n",
    "\n",
    "adf_result = adfuller(jpm_return)\n",
    "print(\"ADF Statistic:\", adf_result[0])\n",
    "print(\"p-value:\", adf_result[1])\n",
    "print(\"Critical Values:\", adf_result[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive (AR) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X_t = \\phi_0 + \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\dots + \\phi_p X_{t-p} + \\epsilon_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PACF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When modeling real data with an AR model, the order $p$ is unknown. Determining $p$ is called the problem of order selection. Common methods include the partial autocorrelation function (PACF) and the AIC or BIC criterion.\n",
    "\n",
    "Let $X_1, \\ldots, X_n, Y$ be random variables, and define\n",
    "\n",
    "$$\n",
    "L(Y|X_1, \\ldots, X_n) = \\arg\\min_{\\hat{Y}=b_0+b_1X_1+\\cdots+b_nX_n} E(Y-\\hat{Y})^2,\n",
    "$$\n",
    "\n",
    "which is called the best linear prediction of $Y$ using $X_1, \\ldots, X_n$. The correlation coefficient between $Y - L(Y|X_1, \\ldots, X_n)$ and $Z - L(Z|X_1, \\ldots, X_n)$ is called the **partial correlation coefficient** between $Y$ and $Z$ after removing the effect of $X_1, \\ldots, X_n$.\n",
    "\n",
    "For a stationary linear time series, for $n=1,2,\\ldots$, we have\n",
    "\n",
    "$$\n",
    "L(X_t | X_{t-1}, \\ldots, X_{t-n}) = \\phi_{n0} + \\phi_{n1} X_{t-1} + \\cdots + \\phi_{nn} X_{t-n},\n",
    "$$\n",
    "\n",
    "where $\\phi_{nj}, j=0,1,\\ldots,n$ are independent of $t$. $\\phi_{nn}$ is the **partial autocorrelation coefficient** of the time series $\\{X_t\\}$, and the sequence $\\{\\phi_{nn}\\}$ is called the **partial autocorrelation function (PACF)** of the time series $\\{X_t\\}$.\n",
    "\n",
    "In fact, $\\phi_{nn}$ is the partial correlation coefficient between $X_t$ and $X_{t-n}$ after removing the effect of $X_{t-1}, \\ldots, X_{t-(n-1)}$. In particular, $\\phi_{11} = \\rho_1$.\n",
    "\n",
    "The sample estimate of $\\phi_{nn}$, denoted $\\hat{\\phi}_{nn}, n=1,2,\\ldots$, is called the **sample partial autocorrelation function**. In Python, it can be estimated and plotted using plot_pacf() from statsmodels.\n",
    "\n",
    "If ${X_t}$ follows the AR($p$) model:\n",
    "\n",
    "$$\n",
    "X_t = \\phi_0 + \\phi_1 X_{t-1} + \\cdots + \\phi_p X_{t-p} + \\varepsilon_t, \\quad \\phi_p \\neq 0,\n",
    "$$\n",
    "\n",
    "this means that when predicting $X_t$ using a linear combination of $X_{t-1}, \\ldots, X_{t-p}$, only these lags are needed. Adding $X_{t-p-1}, X_{t-p-2}, \\ldots$ does not improve the prediction. This implies that $\\hat{\\phi}_{kk}=0, k>p$. This property is called the cut-off property of the PACF for AR models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "plot_pacf(jpm_return, lags=40)\n",
    "plt.title(\"PACF Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(jpm_return, lags=40)\n",
    "plt.title(\"ACF Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are generally 2 ways of fitting a AR model, ARIMA is perfered, standard errors are more precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "ar_model = AutoReg(jpm_data, lags=1).fit()\n",
    "ar_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "ar_model = ARIMA(jpm_data, order=(1, 0, 0)).fit()\n",
    "ar_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akaike Information Criterion\n",
    "\n",
    "It is defined as:\n",
    "\n",
    "$$\n",
    "AIC = -\\frac{2}{T}\\ln(\\text{likelihood value}) + \\frac{2}{T}(\\text{number of parameters}),\n",
    "$$\n",
    "\n",
    "where the likelihood value is the likelihood evaluated at the maximum likelihood estimates of the parameters.  \n",
    "When the model is a higher-order AR(p), i.e., $\\{\\varepsilon_t\\}$ is an independent $N(0,\\sigma^2)$ sequence in the AR(p) model, the AIC formula is:\n",
    "\n",
    "$$\n",
    "AIC(k) = \\ln \\hat{\\sigma}_k^2 + \\frac{2k}{T},\n",
    "$$\n",
    "\n",
    "where $k$ is the order of the model, and $\\hat{\\sigma}_k^2$ is the maximum likelihood estimate of the variance of $\\varepsilon_t$ under order $k$.  \n",
    "$\\ln \\hat{\\sigma}_k^2$ represents the goodness of fit of the model to the data: the smaller the value, the better the fit.  \n",
    "The term $\\frac{2k}{T}$ is a penalty for model complexity: the larger the $k$, the more complex the model, the less stable it is, and the worse its adaptability to future situations.  \n",
    "Choosing $k$ that minimizes $AIC(k)$ within a certain range achieves a trade-off between goodness of fit and model simplicity.\n",
    "\n",
    "---\n",
    "\n",
    "Bayesian Information Criterion\n",
    "\n",
    "Another commonly used information criterion is the BIC. For a higher-order AR model:\n",
    "\n",
    "$$\n",
    "BIC(k) = \\ln \\hat{\\sigma}_k^2 + \\frac{k \\ln T}{T},\n",
    "$$\n",
    "\n",
    "BIC tends to select a lower-order model than AIC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ar_model.aic)\n",
    "print(ar_model.bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_model.bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for next period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_model.forecast(steps = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE: Find the Best Lag Order Using BIC</b>:\n",
    "    <ul>        \n",
    "        <li>Fit an AR model for lag orders ranging from 1 to 10. Hint: Use statsmodels ARIMA function.</li> \n",
    "        <li>For each lag order, calculate the BIC values of the fitted AR model.</li>\n",
    "        <li>Create a list to store the  BIC values corresponding to each lag order.</li>\n",
    "        <li>Find the lag order with the minimum BIC values.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_residuals = ar_model.resid\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ar_residuals, label='Residuals', color='blue')\n",
    "plt.title(\"Residuals Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Ljung-Box test\n",
    "ljung_box_result = acorr_ljungbox(ar_residuals, lags=[np.floor(np.sqrt(len(jpm_return)))], return_df=True)\n",
    "print(ljung_box_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Average (MA) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X_t = \\mu + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\dots + \\theta_q \\epsilon_{t-q}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MA (Moving Average) model describes the current value (the value of the time series) as being determined by the weighted sum of random error terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the lag using Autocorrelation Function(ACF) plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(jpm_return, lags=40)\n",
    "plt.title(\"ACF Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_model = ARIMA(jpm_return, order=(0, 0, 2)).fit()\n",
    "ma_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for next period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = ma_model.forecast(steps=1)\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_residuals = ma_model.resid\n",
    "\n",
    "ljung_box_result = acorr_ljungbox(ma_residuals, lags=[np.floor(np.sqrt(len(jpm_return)))], return_df=True)\n",
    "print(ljung_box_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive Moving Average (ARMA) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X_t = \\mu + \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\dots + \\phi_p X_{t-p} + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\dots + \\theta_q \\epsilon_{t-q}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_model = ARIMA(jpm_return, order=(2, 0, 2)).fit()\n",
    "arma_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_model.forecast(steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_residuals = arma_model.resid\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(arma_residuals, label='Residuals', color='blue')\n",
    "plt.title(\"Residuals Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ljung_box_result = acorr_ljungbox(arma_residuals, lags=[np.floor(np.sqrt(len(jpm_return)))], return_df=True)\n",
    "print(ljung_box_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Autoregressive Conditional Heteroskedasticity (GARCH) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X_t = \\mu + \\epsilon_t\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\epsilon_t = \\sigma_t z_t\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_t^2 = \\alpha_0 + \\sum_{i=1}^{q} \\alpha_i \\epsilon_{t-i}^2 + \\sum_{j=1}^{p} \\beta_j \\sigma_{t-j}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose mean = 'Zero', 'Constant', 'AR'\n",
    "\n",
    "dist = 'Normal', 't', 'skewt', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garch_model = arch_model(jpm_return, mean='Zero', vol='GARCH', p=1, q=1, dist='Normal').fit()\n",
    "garch_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract residuals\n",
    "eps = garch_model.resid               # epsilon_t\n",
    "sigma = res.conditional_volatility    # sigma_t\n",
    "z = res.std_resid                    # standardized residuals: z_t = eps_t / sigma_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals over time\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(eps, lw=0.8)\n",
    "plt.title(\"Residuals (epsilon_t)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Standardized residuals over time\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(z, lw=0.8)\n",
    "plt.title(\"Standardized Residuals (z_t)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"z_t\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, probplot, skew, kurtosis\n",
    "\n",
    "# Histogram of z with standard normal pdf\n",
    "plt.figure(figsize=(6, 4))\n",
    "count, bins, _ = plt.hist(z, bins=50, density=True, alpha=0.5, edgecolor=\"none\", label=\"z_t histogram\")\n",
    "x = np.linspace(z.min(), z.max(), 400)\n",
    "plt.plot(x, norm.pdf(x), \"k--\", label=\"N(0,1) pdf\")\n",
    "plt.title(\"Standardized Residuals: Histogram vs N(0,1)\")\n",
    "plt.xlabel(\"z_t\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Normal Q-Q plot for z\n",
    "plt.figure(figsize=(4.5, 4.5))\n",
    "probplot(z, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q Plot of z_t\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t as student_t, probplot\n",
    "\n",
    "am_t = arch_model(jpm_return, mean='Zero', vol='GARCH', p=1, q=1, dist='t')\n",
    "res_t = am_t.fit()\n",
    "\n",
    "#Extract standardized residuals and estimated df\n",
    "z_t = res_t.std_resid     # standardized residuals: epsilon_t / sigma_t\n",
    "df_t = float(res_t.params.get(\"nu\"))  # estimated degrees of freedom\n",
    "\n",
    "#Histogram with Student-t pdf \n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(z_t, bins=50, density=True, alpha=0.5, edgecolor=\"none\", label=\"z_t histogram\")\n",
    "x = np.linspace(z_t.min(), z_t.max(), 400)\n",
    "plt.plot(x, student_t.pdf(x, df=df_t), \"r--\", label=f\"t pdf (df={df_t:.1f})\")\n",
    "plt.title(\"Standardized Residuals: Histogram vs t pdf\")\n",
    "plt.xlabel(\"z_t\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Student-t Q-Q plot for z_t\n",
    "plt.figure(figsize=(4.5, 4.5))\n",
    "probplot(z_t, dist=student_t, sparams=(df_t,), plot=plt)\n",
    "plt.title(f\"t Q-Q Plot of z_t (df≈{df_t:.1f})\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for next period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_t.forecast(horizon=1).variance.values[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE:</b>\n",
    "    <ul>\n",
    "        <li>Write a loop to find the best GARCH model order (<code>p</code>, <code>q</code>) where <code>p</code> ranges from 1 to 5 and <code>q</code> ranges from 1 to 5, using the Bayesian Information Criterion (BIC) for selection.</li>\n",
    "        <li>Using a rolling window of 252 observations, predict the volatility for the next period for each window.</li>\n",
    "        <li>Plot the squared predicted volatility against the squared returns for comparison.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import\n",
    "\n",
    "We use the Boston real estate price data.\n",
    "\n",
    "The first 401 observations are used for the estimation of a linear regression and the following observations for the calculation of the forecasts and the measurement of the precision of these forecasts by various criteria.\n",
    "\n",
    "\n",
    "We will estimate two regressions:\n",
    "    \n",
    "     * regression of 'MEDV' (denoted y) on 'RM' denoted (x)\n",
    "     * regression of 'MEDV' on all the other variables noted X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "data = pd.read_csv('housing.csv', header=None, delimiter=r\"\\s+\", names=column_names)\n",
    "# Separate the data into two sub-samples\n",
    "# sample 1: up to index 400\n",
    "# sample 2: from index 401\n",
    "y1 = data.loc[:400,'MEDV'] #data.iloc[:401,-1]\n",
    "y2 = data.loc[401:,'MEDV'] #data.iloc[401:,-1]\n",
    "x1 = data.loc[:400,'RM']  \n",
    "x2 = data.loc[401:,'RM'] \n",
    "X1 = data.loc[:400,data.columns!='MEDV'] \n",
    "X2 = data.loc[401:,data.columns!='MEDV'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear regression with scikit-learn\n",
    "\n",
    "Estimating a simple linear regression with **scikit-learn** involves 5 steps:\n",
    "    \n",
    "     1. import necessary packages and object classes\n",
    "    \n",
    "     2. Importing data and performing appropriate transformations\n",
    "    \n",
    "     3. Creation and Estimation of a Regression Model\n",
    "    \n",
    "     4. Checking the estimation results\n",
    "    \n",
    "     5. forecast with the estimated model\n",
    "    \n",
    "    \n",
    "   \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.linear_model.LinearRegression allows to estimate linear or polynomial regressions and to calculate forecasts with the estimated models.\n",
    "\n",
    "### Collection of data\n",
    "\n",
    "We transform the series **y** and **x** into numpy.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x1)\n",
    "y=np.array(y1)\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must transform x into an array of dimension 2: one column and many rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a model and estimating with existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalent writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the results of a regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimated coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.intercept_, model.coef_)#note the underscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $R^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq =model.score(x,y)\n",
    "print(f\"determination coefficient: {r_sq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast: calculation of adjusted variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred =np.array(x2)\n",
    "x_pred =x_pred[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"predicted variable:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative method: by calculating y_pred from the linear regression formula\n",
    "\n",
    "y_pred2 = model.intercept_ + model.coef_*x_pred\n",
    "print(f\"predicted answer from calculation formula:\\n{y_pred2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of forecast accuracy indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean squared error: %.2f\" %mean_squared_error(y2,y_pred))\n",
    "print(\"Mean absolute error: %.2f\" %mean_absolute_error(y2,y_pred))\n",
    "print(\"Mean absolute percentage error: %.2f\" %mean_absolute_percentage_error(y2,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphics with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plt.scatter() to plot the actual data and plt.plot() to plot the predicted line\n",
    "plt.scatter(x2,y2,color=\"black\")\n",
    "plt.plot(x2,y_pred,color=\"blue\",linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple linear regression with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelall = LinearRegression().fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelall.intercept_, modelall.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq = modelall.score(X,y)\n",
    "r_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.array(X2)\n",
    "yall_pred = modelall.predict(x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yall_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean squared error: %.2f\" %mean_squared_error(y2,y_pred))\n",
    "print(\"Mean absolute error: %.2f\" %mean_absolute_error(y2,y_pred))\n",
    "print(\"Mean absolute percentage error: %.2f\" %mean_absolute_percentage_error(y2,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y2,yall_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y2,yall_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(y2,yall_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regressions with statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=sm.add_constant(X1) # statsmodels does not add a default constant in linear regressions. It needs to be added.\n",
    "regall=sm.OLS(y1,X1).fit()\n",
    "regall.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display of estimated coefficients\n",
    "regall.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display of the t-stat of the estimated coefficients\n",
    "regall.tvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display pvalue of the F-stat\n",
    "regall.f_pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "sns.heatmap(data.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to check that the correlation is significantly different from 0\n",
    "from scipy import stats\n",
    "stats.pearsonr(data['AGE'].to_numpy(),data['DIS'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display R² and adjusted R²\n",
    "regall.rsquared, regall.rsquared_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display of residuals\n",
    "regall.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regall.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(regall) # list of all objects that can be retrieved from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### specification test and residue tests\n",
    "\n",
    "https://www.statsmodels.org/stable/stats.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.stats.stattools.durbin_watson(regall.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating models with a formula\n",
    "we use the library **statsmodels.formula.api**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smf.ols allows the direct use of formula strings similar to those in R language to define the model, which can include interaction terms, polynomial terms, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = smf.ols('MEDV~CRIM+PTRATIO',data=data).fit() # lowercase ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## display results\n",
    "reg1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present the estimation of a regression by OLS. However, you can also do:\n",
    "    \n",
    "* GLS: generalized least squares\n",
    "    \n",
    "* WLS: weighted least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming a linear regression\n",
    "\n",
    "### Linear regression model\n",
    "We assume that we have $P$ pairs of variables $(y_{p},x_{p})$ where $y_{p}$ is the explained variable and $x_{p}=(x_{1p} ,...,x_{Np})^{T}$ is the column vector of the $N$ explanatory variables (for the individual $p$).\n",
    "These variables are linked by the linear relationship:\n",
    "$$\n",
    "y_{p}= w_{0} + \\sum_{i}^{N} w_{i} x_{ip} + e_{p} = w_{0} + x_{p}^{T}w + e_{ p}\n",
    "$$\n",
    "where $w=(w_{1},w_{2},...w_{N})^{T}$ is the (N,1) vector of coefficients.\n",
    "\n",
    "We note $w^{*} = (w_{0},w_{1},...,w_{N})^{T}$ the vector of dimensions (N+1,1) containing the constant $w_ {0}$ and $w$.\n",
    "\n",
    "\n",
    "Build a Python function, called **model(x,w)**, having as arguments (inputs) $x$ and $w^{*}$ and returning (output) the adjusted values $N$ : $w_{0 } + x_{p}'w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we use the np.dot() matrix product of numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistical modeling and practical implementation, e typically represents the error term or random disturbance. When building predictive models, our goal is to estimate model parameters (i.e., coefficients w and the constant term w0 so that we can use these estimates to predict or explain the dependent variable y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function\n",
    "\n",
    "We note $y=(y_{1}, y_{2},...,y_{P})$ the sequence of $1 \\times P$ explained variables and $x = (x_{1},..., x_{P})$ the (N,p) matrix of explanatory variables.\n",
    "\n",
    "We are looking for the parameters $w^{*}$ which minimize the least squares cost function:\n",
    "     $$\n",
    "     c(w^{*},x,y) = \\frac{1}{P} \\sum_{i=1}^{P} (y_{i} - w_{0}-x^{T}_{ i}w)^{2}\n",
    "     $$\n",
    "    \n",
    "Build a python function **least_squares(w)** having as arguments $w^{*}, x,y$ and returning the cost function $c(w^{*},x,y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "x =\n",
    "\\begin{bmatrix}\n",
    "x_{11} & x_{12} & \\dots & x_{1P} \\\\\n",
    "x_{21} & x_{22} & \\dots & x_{2P} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{N1} & x_{N2} & \\dots & x_{NP} \\\\\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid making the loop, we can use the Numpy function np.sum which calculates the sum of the elements of an array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Stability of $ \\beta_i $\n",
    "\n",
    "We consider the following decomposition of the return of an asset $ i $:\n",
    "\n",
    "$$\n",
    "r_{it} = \\alpha_i + \\beta_i r_{mt} + e_{it}\n",
    "$$\n",
    "\n",
    "where $ r_{it} $ is the return on asset $ i $ and $ r_{mt} $ is the return on the stock market index. The term $ \\beta_i r_{mt} $ measures the common variations to all assets, the residual $ e_{it} $ represents the specific risk of each asset.\n",
    "\n",
    "The value of $ \\beta_i $ determines the risk of asset $ i $ relative to the market portfolio:\n",
    "\n",
    "- $ \\beta_i = 1 $: asset $ i $ is as risky as the market portfolio.\n",
    "- $ \\beta_i < 1 $: asset $ i $ is less risky than the market portfolio.\n",
    "- $ \\beta_i > 1 $: asset $ i $ is more risky than the market portfolio.\n",
    "\n",
    "\n",
    "---\n",
    "1. **Import Excercise.csv**\n",
    "\n",
    "2. **Select 10 securities at random.** For each of the $ n = 10 $ securities, estimate by the **OLS regression**: $ r_{it} = \\alpha_i + \\beta_i r_{mt} + e_{it} $ with $ t = 1, \\dots, 40 $ first observations. The estimated model is noted\n",
    "\n",
    "    $$\n",
    "    r_{it} = \\hat{\\alpha}_i + \\hat{\\beta}_i r_{mt} + \\hat{e}_{it}, \\quad t = 1, \\dots, 40\n",
    "    $$\n",
    "\n",
    "    We note $ \\beta_{i,40} $ as the $ \\beta $ of asset $ i $ obtained from the 40 first observations.\n",
    "\n",
    "3. **Estimate the same regression** for the equally weighted portfolio of $ n = 10 $ securities $ r_{pt} = \\frac{1}{n} \\sum_{i=1}^{n} r_{it} $\n",
    "\n",
    "    $$\n",
    "    r_{pt} = \\alpha_p + \\beta_p r_{mt} + e_{pt}, \\quad t = 1, \\dots, 40\n",
    "    $$\n",
    "\n",
    "    It can be shown that $ \\alpha_p = \\frac{1}{n} \\sum_{i=1}^{n} \\alpha_i $ and $ \\beta_p = \\frac{1}{n} \\sum_{i=1}^{n} \\beta_i $.\n",
    "\n",
    "4. **Re-estimate the previous regressions for each security and the portfolio** by adding the following observations one by one to the first 40 observations. We will obtain for each asset a sequence of $ \\beta_{i,40}, \\beta_{i,41}, \\dots, \\beta_{i,T} $ where $ T $ is the end date of the sample. For each sequence of $ \\beta_{i,40}, \\beta_{i,41}, \\dots, \\beta_{i,T} $, calculate:\n",
    "\n",
    "    - the mean,\n",
    "    - the minimum, the maximum,\n",
    "    - the standard deviation\n",
    "      \n",
    "5. **Plot the evolution of the estimated betas over time**\n",
    "Using matplotlib, represent on a single graph the evolution of the coefficients $ \\beta_{i,t} $ for the 10 selected securities as the estimation window grows from 40 to $T$.\n",
    "Each line should show how the estimated beta of a given stock evolves as new data are added to the regression. Commetn on the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
